{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression/Linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset with some features (or predictors, independent variables) and a label/discrete variable (classification) or a number/continuous variable (regression) to predict.\n",
    "\n",
    "```Y = f(X) + error-term```\n",
    "\n",
    "LR is part of statistical learning, where we use a set of approaches for estimating f (a linear function) in order to predict Y using\n",
    "\n",
    "```Y^ = f^(X) = w0 + w1x1 + w2x2 + .... (x1,x2 ... are predictors; w0,w1,w2 are weights/coefficients)```\n",
    "\n",
    "This is known as a parametric method (where we make a few assumption about the function form or shape, in this case, the assumption is linear function and several concomitant condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the linear function: its coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE or RSS (Sum of square with no mean) are functions that only has one global (convex quadratic function).\n",
    "\n",
    "2 ways:\n",
    "\n",
    "- mathematics: with Least square coefficient estimate?\n",
    "- Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate LR predicted weights/ coefficients with Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use formula in other note. Only explanations here</b>\n",
    "\n",
    "We use a confidence interval to quantify the uncertainty surrounding confidence the average sales over a large number of cities.\n",
    "\n",
    "For example, given that Xtv = \\\\$100,000 is spent on TV advertising and Xradio = \\\\$20,000 is spent on radio advertising in each city, the 95 % confidence interval for sale is [10,985, 11,528]. We interpret this as: 95 % of intervals of this form will contain the true value of f(Xtv,Xradio)\n",
    "\n",
    "In other words, if we collect a large number of data sets like the Advertising dataset (taking a big sample from a population), and we construct a confidence interval for the average sales on the basis of each data set (given \\\\$100,000 in TV and \\\\$20,000 in radio advertising), then 95 % of these confidence intervals will contain the true value of average sales.\n",
    "\n",
    "\n",
    "#### Use Prediction Interval (instead of Confidence Interval) to evaluate prediction with irreducible error\n",
    "As a result, Prediction interval tends to be wider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors are not correlated with another\n",
    "\n",
    "Example of correlated error: \n",
    "- Accidently include a duplicate of the data => error is duplicate => correlated error\n",
    "- Time series data: obervations at near timeline will have positively correlated errors\n",
    "- Data collected from people who subtly belong to groups (family, neighborhood)\n",
    "\n",
    "To spot correlated error, use residual plot\n",
    "\n",
    "Effect of correlated error: Estimated standard error < true SE, meaning confidence interval is smaller AND p-values will get smaller, meaning some features will become significant, even though they are not (p-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors are normally distributed (meaning they have constant variance)\n",
    "\n",
    "If the errors are skewed in some way, log them so they become normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers of features\n",
    "\n",
    "Data point can become outlier due to 1 outlier feature or 2 outlier features (E.g. for two features X1 and X2, individually they are still within their range, but together they stand out)\n",
    "\n",
    "Calculate leverage statistics to see which one stands out, then remove them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Little feature interaction/ Features are independent (an increase in one won't result in an increase in another)\n",
    "\n",
    "If there are some interaction between features, add interaction term (a new feature which is a multiplication of the 2 interacting features)\n",
    "\n",
    "To check if there is even such interaction: create this feature and see whether the p-value is significant\n",
    "\n",
    "Note: \n",
    "- aware of the dangers of performing regressions with only 1 single and neglect other features (that may be relevant)\n",
    "- 1-feature regression can be vastly different from multiple-feature regression, <b>especially when there is feature correlation</b>. (Review the student-balance correlation in credit-card default rate problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No collinearity\n",
    "\n",
    "When features relate to each other (similar to features dependent above?) = colinearity\n",
    "- mess up loss contour, results in multiple feature pairs that have the same value for loss\n",
    "- cause standard error to grow => bigger CI and p-values higher => features no longer statistically significant\n",
    "\n",
    "\n",
    "<b>To detect bi-collinearity</b>: plot it, or use correlation matrix\n",
    "\n",
    "<b>To detect multi-collinearity</b>: calculate VIF (variance infaltion factor), which is based on R2 square from a regression of feature X1 onto all of other features. If R2 is high => X1 can be predicted from other features\n",
    "\n",
    "What to do with high collinearity features?\n",
    "- Drop them\n",
    "- Combine them (average them) into a new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pros and Cons of using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- Easy to fit\n",
    "- Can interpret model and effects of each features at ease\n",
    "- Statistical sigficance test can be performed\n",
    "\n",
    "Cons:\n",
    "- Strong assumptions about data\n",
    "- Strong assumptions about predicting functions (linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
